{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f23d326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "hr_path = 'E:\\\\dl_data\\\\SR\\\\open_sr\\\\train\\\\hr\\\\'\n",
    "\n",
    "new_hr_path = 'E:\\\\dl_data\\\\SR\\\\open_sr_gen\\\\hr\\\\'\n",
    "new_lr_path = 'E:\\\\dl_data\\\\SR\\\\open_sr_gen\\\\lr\\\\'\n",
    "new_hr_valid_path = 'E:\\\\dl_data\\\\SR\\\\open_sr_gen\\\\hr_valid\\\\'\n",
    "new_lr_valid_path = 'E:\\\\dl_data\\\\SR\\\\open_sr_gen\\\\lr_valid\\\\'\n",
    "path_splitter = '\\\\'\n",
    "\n",
    "os.makedirs(new_hr_path, exist_ok=True)\n",
    "os.makedirs(new_lr_path, exist_ok=True)\n",
    "os.makedirs(new_hr_valid_path, exist_ok=True)\n",
    "os.makedirs(new_lr_valid_path, exist_ok=True)\n",
    "\n",
    "target_width = 512\n",
    "target_height = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c74393a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1640/1640 [04:39<00:00,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "target_width = 512\n",
    "target_height = 512\n",
    "\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import os, shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# remove old files\n",
    "filelist = glob(os.path.join(new_hr_path, \"*\"))\n",
    "for f in filelist:\n",
    "    os.remove(f)\n",
    "filelist = glob(os.path.join(new_lr_path, \"*\"))\n",
    "for f in filelist:\n",
    "    os.remove(f)\n",
    "filelist = glob(os.path.join(new_hr_valid_path, \"*\"))\n",
    "for f in filelist:\n",
    "    os.remove(f)\n",
    "filelist = glob(os.path.join(new_lr_valid_path, \"*\"))\n",
    "for f in filelist:\n",
    "    os.remove(f)\n",
    "\n",
    "# variables\n",
    "total_count = 0\n",
    "designated_valid_count = 12\n",
    "current_count = 0\n",
    "do_each = False\n",
    "\n",
    "#\n",
    "filelist = glob(os.path.join(hr_path, \"*.png\"))\n",
    "if total_count == 0:\n",
    "    total_count = len(filelist)\n",
    "    \n",
    "for _, file in enumerate(tqdm(filelist)):\n",
    "    filename = file.split(path_splitter)[-1]\n",
    "    filename_without_ext = filename.split('.')[0]   \n",
    "\n",
    "    ### resize or filter\n",
    "    modes = ['nearest', 'box', 'bilinear', 'hamming', 'bicubic', 'lanczos', 'blur', 'gaussian_blur', 'median_blur', 'bilateral_filter']\n",
    "    applys = [True, False, True, False, True, True, False, True, False, True]\n",
    "    \n",
    "    #\n",
    "    do_modes = []\n",
    "    for index, mode in enumerate(modes):\n",
    "        if applys[index] is True:\n",
    "            do_modes.append(mode)\n",
    "    if do_each is False: # 파일마다 한번씩만 round robin\n",
    "        do_mode = do_modes[current_count % len(do_modes)]\n",
    "        do_modes.clear()\n",
    "        do_modes.append(do_mode)\n",
    "        \n",
    "    # train or valid\n",
    "    for_valid = False\n",
    "    if current_count + designated_valid_count >= total_count:\n",
    "        for_valid = True\n",
    "\n",
    "    target_hr_path = new_hr_path\n",
    "    target_lr_path = new_lr_path\n",
    "    if for_valid is True:\n",
    "        target_hr_path = new_hr_valid_path\n",
    "        target_lr_path = new_lr_valid_path\n",
    "    \n",
    "    for mode in do_modes:\n",
    "        if mode in ['nearest', 'box', 'bilinear', 'hamming', 'bicubic', 'lanczos']:\n",
    "            # resize\n",
    "            img = Image.open(file)\n",
    "            if mode == 'nearest':\n",
    "                img_resize = img.resize((target_width, target_height), Image.Resampling.NEAREST)\n",
    "            elif mode == 'box':\n",
    "                img_resize = img.resize((target_width, target_height), Image.Resampling.BOX)\n",
    "            elif mode == 'bilinear':\n",
    "                img_resize = img.resize((target_width, target_height), Image.Resampling.BILINEAR)\n",
    "            elif mode == 'hamming':\n",
    "                img_resize = img.resize((target_width, target_height), Image.Resampling.HAMMING)\n",
    "            elif mode == 'bicubic':\n",
    "                img_resize = img.resize((target_width, target_height), Image.Resampling.BICUBIC)\n",
    "            elif mode == 'lanczos':\n",
    "                img_resize = img.resize((target_width, target_height), Image.Resampling.LANCZOS)\n",
    "                \n",
    "            # copy hr\n",
    "            new_file_hr = target_hr_path + filename_without_ext + \"_\" + mode + \".png\"\n",
    "            shutil.copy(file, new_file_hr)\n",
    "            # copy lr\n",
    "            new_file_lr = target_lr_path + filename_without_ext + \"_\" + mode + \".png\"\n",
    "            img_resize.save(new_file_lr)\n",
    "        \n",
    "            #print(filename + ' ' + mode + ' done')\n",
    "        else:\n",
    "            img = cv2.imread(file)\n",
    "            resize_img = cv2.resize(img, (target_width, target_height))   \n",
    "            if mode == 'blur':\n",
    "                dst = cv2.blur(resize_img, (5,5))\n",
    "            elif mode == 'gaussian_blur':\n",
    "                dst = cv2.GaussianBlur(resize_img, (5,5), 0)\n",
    "            elif mode == 'median_blur':\n",
    "                dst = cv2.medianBlur(resize_img, 5)\n",
    "            elif mode == 'bilateral_filter':\n",
    "                dst = cv2.bilateralFilter(resize_img, 9, 75, 75)\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            # copy hr\n",
    "            new_file_hr = target_hr_path + filename_without_ext + \"_\" + mode + \".png\"\n",
    "            shutil.copy(file, new_file_hr)\n",
    "            # copy lr\n",
    "            new_file_lr = target_lr_path + filename_without_ext + \"_\" + mode + \".png\"\n",
    "            cv2.imwrite(new_file_lr, dst)\n",
    "\n",
    "            #print(filename + ' ' + mode + ' done')\n",
    "    \n",
    "    current_count += 1\n",
    "    #if current_count > 10:\n",
    "    #    break\n",
    "    \n",
    "print('all done')\n",
    "\n",
    "### 컨볼루션\n",
    "#img = cv2.imread(hr_path + filename)\n",
    "#resize_img = cv2.resize(img, (target_width, target_height))\n",
    "#kernel = np.ones((5,5),np.float32)/25\n",
    "#dst = cv2.filter2D(resize_img, -1, kernel)\n",
    "#new_file = lr_path + '7_convolution_' + filename\n",
    "#cv2.imwrite(new_file, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376c11a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
