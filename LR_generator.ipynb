{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ea022f-45a4-45bc-8559-9b7784a38d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## hr 과 lr 을 train / valid 로 분리\n",
    "from glob import glob\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "base_paths = ['/home/jovyan/playGround/ziippy/dl_data/open_sr/train/hr/', \n",
    "             '/home/jovyan/playGround/ziippy/dl_data/open_sr/train/lr/']\n",
    "new_train_paths = ['/home/jovyan/playGround/ziippy/dl_data/open_sr/train/hr_split_train/',\n",
    "                  '/home/jovyan/playGround/ziippy/dl_data/open_sr/train/lr_split_train/']\n",
    "new_valid_paths = ['/home/jovyan/playGround/ziippy/dl_data/open_sr/train/hr_split_valid/',\n",
    "                  '/home/jovyan/playGround/ziippy/dl_data/open_sr/train/lr_split_valid/']\n",
    "\n",
    "random.seed(2022)\n",
    "\n",
    "for index, base_path in enumerate(base_paths):\n",
    "    new_train_path = new_train_paths[index]\n",
    "    new_valid_path = new_valid_paths[index]\n",
    "    \n",
    "    print(new_train_path)\n",
    "    print(new_valid_path)\n",
    "    \n",
    "    shutil.rmtree(new_train_path, ignore_errors=True)\n",
    "    os.makedirs(new_train_path, exist_ok=True)\n",
    "    shutil.rmtree(new_valid_path, ignore_errors=True)\n",
    "    os.makedirs(new_valid_path, exist_ok=True)\n",
    "\n",
    "    file_list = glob(base_path + '*.png')\n",
    "    file_count = len(file_list)\n",
    "    print(file_count)\n",
    "    \n",
    "    file_list.sort()\n",
    "\n",
    "    #random.shuffle(file_list)\n",
    "\n",
    "    train_ratio = 0.975\n",
    "    train_index = int(file_count * train_ratio)\n",
    "    print(train_index)\n",
    "    print(file_count - train_index)\n",
    "\n",
    "    for file in file_list[:train_index]:\n",
    "        filename = file.split('/')[-1]\n",
    "        shutil.copy(file, new_train_path+filename)\n",
    "        #print(filename)    \n",
    "    print('split for train done')\n",
    "\n",
    "    for file in file_list[train_index:]:\n",
    "        filename = file.split('/')[-1]\n",
    "        shutil.copy(file, new_valid_path+filename)\n",
    "        #print(filename)\n",
    "    print('split for valid done')\n",
    "    \n",
    "print('all done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb6b5b9b-a522-4f7c-bdda-405bc650de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "hr_path = '/home/jovyan/playGround/ziippy/dl_data/open_sr/train/hr_split_train/'\n",
    "lr_path = '/home/jovyan/playGround/ziippy/dl_data/open_sr/train/lr_split_train/'\n",
    "\n",
    "new_hr_path = '/home/jovyan/playGround/ziippy/dl_data/open_sr/train/new_hr/'\n",
    "new_lr_path = '/home/jovyan/playGround/ziippy/dl_data/open_sr/train/new_lr/'\n",
    "new_hr_valid_path = '/home/jovyan/playGround/ziippy/dl_data/open_sr/train/new_hr_valid/'\n",
    "new_lr_valid_path = '/home/jovyan/playGround/ziippy/dl_data/open_sr/train/new_lr_valid/'\n",
    "path_splitter = '/'\n",
    "\n",
    "os.makedirs(new_hr_path, exist_ok=True)\n",
    "os.makedirs(new_lr_path, exist_ok=True)\n",
    "os.makedirs(new_hr_valid_path, exist_ok=True)\n",
    "os.makedirs(new_lr_valid_path, exist_ok=True)\n",
    "\n",
    "target_width = 512\n",
    "target_height = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1759031b-73f1-4e6e-8cd0-51d4caa59113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1599/1599 [00:12<00:00, 123.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy original hr done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1599/1599 [00:06<00:00, 233.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy original lr done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1599/1599 [04:38<00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "target_width = 512\n",
    "target_height = 512\n",
    "\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import os, shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# remove old files\n",
    "filelist = glob(os.path.join(new_hr_path, \"*\"))\n",
    "for f in filelist:\n",
    "    os.remove(f)\n",
    "filelist = glob(os.path.join(new_lr_path, \"*\"))\n",
    "for f in filelist:\n",
    "    os.remove(f)\n",
    "filelist = glob(os.path.join(new_hr_valid_path, \"*\"))\n",
    "for f in filelist:\n",
    "    os.remove(f)\n",
    "filelist = glob(os.path.join(new_lr_valid_path, \"*\"))\n",
    "for f in filelist:\n",
    "    os.remove(f)\n",
    "\n",
    "# variables\n",
    "total_count = 0\n",
    "designated_valid_count = 60\n",
    "current_count = 0\n",
    "do_each = False\n",
    "train_ratio = 1.0\n",
    "using_original = True\n",
    "   \n",
    "# hr\n",
    "filelist = glob(os.path.join(hr_path, \"*.png\"))\n",
    "filelist.sort()\n",
    "\n",
    "total_count = len(filelist)\n",
    "train_index = int(total_count * train_ratio)\n",
    "\n",
    "if using_original is True:\n",
    "    org_hr_list = glob(os.path.join(hr_path, \"*.png\"))\n",
    "    for file in tqdm(org_hr_list[:train_index]):\n",
    "        filename = file.split('/')[-1]\n",
    "        shutil.copy(file, new_hr_path + filename)\n",
    "    print('copy original hr done')\n",
    "\n",
    "    org_lr_list = glob(os.path.join(lr_path, \"*.png\"))\n",
    "    for file in tqdm(org_lr_list[:train_index]):\n",
    "        filename = file.split('/')[-1]\n",
    "        shutil.copy(file, new_lr_path + filename)\n",
    "    print('copy original lr done')\n",
    "\n",
    "for _, file in enumerate(tqdm(filelist[:train_index])):\n",
    "    filename = file.split(path_splitter)[-1]\n",
    "    filename_without_ext = filename.split('.')[0]   \n",
    "\n",
    "    ### resize or filter\n",
    "    modes = ['nearest', 'box', 'bilinear', 'hamming', 'bicubic', 'lanczos', 'blur', 'gaussian_blur', 'median_blur', 'bilateral_filter']\n",
    "    applys = [True, False, True, False, True, True, False, True, False, True]\n",
    "    \n",
    "    #\n",
    "    do_modes = []\n",
    "    for index, mode in enumerate(modes):\n",
    "        if applys[index] is True:\n",
    "            do_modes.append(mode)\n",
    "    if do_each is False: # 파일마다 한번씩만 round robin\n",
    "        do_mode = do_modes[current_count % len(do_modes)]\n",
    "        do_modes.clear()\n",
    "        do_modes.append(do_mode)\n",
    "        \n",
    "    # train or valid\n",
    "    for_valid = False\n",
    "    if current_count + designated_valid_count >= train_index:\n",
    "        for_valid = True\n",
    "\n",
    "    target_hr_path = new_hr_path\n",
    "    target_lr_path = new_lr_path\n",
    "    if for_valid is True:\n",
    "        target_hr_path = new_hr_valid_path\n",
    "        target_lr_path = new_lr_valid_path\n",
    "    \n",
    "    for mode in do_modes:\n",
    "        if mode in ['nearest', 'box', 'bilinear', 'hamming', 'bicubic', 'lanczos']:\n",
    "            # resize\n",
    "            img = Image.open(file)\n",
    "            if mode == 'nearest':\n",
    "                img_resize = img.resize((target_width, target_height), Image.NEAREST)\n",
    "            elif mode == 'box':\n",
    "                img_resize = img.resize((target_width, target_height), Image.BOX)\n",
    "            elif mode == 'bilinear':\n",
    "                img_resize = img.resize((target_width, target_height), Image.BILINEAR)\n",
    "            elif mode == 'hamming':\n",
    "                img_resize = img.resize((target_width, target_height), Image.HAMMING)\n",
    "            elif mode == 'bicubic':\n",
    "                img_resize = img.resize((target_width, target_height), Image.BICUBIC)\n",
    "            elif mode == 'lanczos':\n",
    "                img_resize = img.resize((target_width, target_height), Image.LANCZOS)\n",
    "                \n",
    "            # copy hr\n",
    "            new_file_hr = target_hr_path + filename_without_ext + \"_\" + mode + \".png\"\n",
    "            shutil.copy(file, new_file_hr)\n",
    "            # copy lr\n",
    "            new_file_lr = target_lr_path + filename_without_ext + \"_\" + mode + \".png\"\n",
    "            img_resize.save(new_file_lr)\n",
    "        \n",
    "            #print(filename + ' ' + mode + ' done')\n",
    "        else:\n",
    "            img = cv2.imread(file)\n",
    "            resize_img = cv2.resize(img, (target_width, target_height))   \n",
    "            if mode == 'blur':\n",
    "                dst = cv2.blur(resize_img, (5,5))\n",
    "            elif mode == 'gaussian_blur':\n",
    "                dst = cv2.GaussianBlur(resize_img, (5,5), 0)\n",
    "            elif mode == 'median_blur':\n",
    "                dst = cv2.medianBlur(resize_img, 5)\n",
    "            elif mode == 'bilateral_filter':\n",
    "                dst = cv2.bilateralFilter(resize_img, 9, 75, 75)\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            # copy hr\n",
    "            new_file_hr = target_hr_path + filename_without_ext + \"_\" + mode + \".png\"\n",
    "            shutil.copy(file, new_file_hr)\n",
    "            # copy lr\n",
    "            new_file_lr = target_lr_path + filename_without_ext + \"_\" + mode + \".png\"\n",
    "            cv2.imwrite(new_file_lr, dst)\n",
    "\n",
    "            #print(filename + ' ' + mode + ' done')\n",
    "    \n",
    "    current_count += 1\n",
    "    #if current_count > 10:\n",
    "    #    break\n",
    "    \n",
    "print('all done')\n",
    "\n",
    "### 컨볼루션\n",
    "#img = cv2.imread(hr_path + filename)\n",
    "#resize_img = cv2.resize(img, (target_width, target_height))\n",
    "#kernel = np.ones((5,5),np.float32)/25\n",
    "#dst = cv2.filter2D(resize_img, -1, kernel)\n",
    "#new_file = lr_path + '7_convolution_' + filename\n",
    "#cv2.imwrite(new_file, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2fb746-13bf-4217-aacb-e7e23c28091b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
